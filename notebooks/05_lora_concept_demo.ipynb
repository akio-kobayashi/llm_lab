{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 05. LoRAによるファインチューニング (学習と永続化)\n",
    "\n",
    "このノートブックでは、QLoRAによる学習を行い、その成果（アダプタ）を **Google Driveに保存** します。これにより、別の日に行われる統合演習（07）で、学習したモデルを再利用することができます。\n",
    "\n",
    "## 演習の目的\n",
    "1. 特定の出力形式（JSON）を学習させる。\n",
    "2. 学習した重みをGoogle Driveに保存（永続化）する。\n",
    "\n",
    "## 事前準備\n",
    "Google Colabのメニュー「ランタイム」→「ランタイムのタイプを変更」で **T4 GPU** を選択してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 編集禁止セル\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "from google.colab import drive\n",
    "\n",
    "# 1. Google Driveのマウント (永続保存に必須)\n",
    "if not os.path.isdir('/content/drive'): drive.mount('/content/drive')\n",
    "\n",
    "repo_path = '/content/llm_lab'\n",
    "if os.path.exists(repo_path): !rm -rf {repo_path}\n",
    "!git clone -b stable-base https://github.com/akio-kobayashi/llm_lab.git {repo_path}\n",
    "os.chdir(repo_path)\n",
    "\n",
    "!pip install -q -U transformers accelerate bitsandbytes sentence-transformers faiss-cpu peft trl datasets gradio\n",
    "if 'src' not in sys.path: sys.path.append(os.path.abspath('src'))\n",
    "\n",
    "from src.common import load_llm, generate_text\n",
    "from src.lora import create_lora_model, train_lora\n",
    "from peft import PeftModel\n",
    "print('セットアップが完了しました。')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. モデルの準備と学習前の確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 編集禁止セル\n",
    "base_model, tokenizer = load_llm(use_4bit=True)\n",
    "\n",
    "question = \"『星屑のメモリー』の主人公について教えて。\"\n",
    "instruction = \"回答は必ず以下のJSON形式で出力してください。\\n{ \\\"answer\\\": \\\"...\\\", \\\"confidence\\\": \\\"high|medium|low\\\" }\"\n",
    "prompt = f\"以下は、タスクを説明する指示です。要求を適切に満たす応答を書きなさい。\\n\\n### 指示:\\n{question}\\n{instruction}\\n\\n### 応答:\\n\"\n",
    "\n",
    "print(\"--- 学習前の回答 (JSON形式が守られないことが多い) ---\")\n",
    "res = generate_text(base_model, tokenizer, prompt, max_new_tokens=128)\n",
    "print(res.split(\"### 応答:\")[-1].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. LoRA学習の実行とGoogle Driveへの保存\n",
    "\n",
    "学習したアダプタをGoogle Driveの `llm_lab_outputs/demo_adapter` フォルダに保存します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 編集禁止セル\n",
    "# 保存先パスの設定 (Google Drive)\n",
    "adapter_dir = \"/content/drive/MyDrive/llm_lab_outputs/demo_adapter\"\n",
    "os.makedirs(adapter_dir, exist_ok=True)\n",
    "\n",
    "print(\"1. LoRAアダプタをモデルに追加中...\")\n",
    "lora_model = create_lora_model(base_model)\n",
    "\n",
    "print(\"2. 簡易学習を開始します（約3〜5分）...\")\n",
    "train_lora(\n",
    "    model=lora_model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset_path='data/lora/lora_train_sample.jsonl',\n",
    "    output_dir=adapter_dir,\n",
    "    max_steps=40,\n",
    "    learning_rate=5e-5\n",
    ")\n",
    "\n",
    "print(f\"学習が完了し、Google Driveに保存されました: {adapter_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 学習後の効果確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 編集禁止セル\n",
    "print(\"--- 学習後の回答 (JSON形式が安定する) ---\")\n",
    "res = generate_text(lora_model, tokenizer, prompt, max_new_tokens=128)\n",
    "print(res.split(\"### 応答:\")[-1].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## まとめ\n",
    "Google Driveに保存されたこのアダプタは、次の **07. 統合デモ** で読み込んで使用します。セッションを終了しても大丈夫です。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": { "display_name": "Python 3", "name": "python3" },
  "language_info": { "name": "python", "version": "3.10.12" }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
